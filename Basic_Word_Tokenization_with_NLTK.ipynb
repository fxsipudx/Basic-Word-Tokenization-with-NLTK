{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAdIzqufZtqk6iv+zWlQA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fxsipudx/Basic-Word-Tokenization-with-NLTK/blob/main/Basic_Word_Tokenization_with_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtri0p8wQr3D",
        "outputId": "c2a6c3db-77c5-4a17-c3db-8dcb04a8b21c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('punkt')  # Download required data for tokenization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgwd4i7JQ6Pj",
        "outputId": "ce8dfbb9-1897-4cd0-c4e9-2c59f3a3db28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a text with 4 sentences\n",
        "text = \"Lionel Messi and Cristiano Ronaldo are football icons. Messi is known for his finesse, while Ronaldo stands out for his power. They’ve set records and won countless awards. Together, they define a legendary rivalry in football history.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Total Number of Tokens:\", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQbraOirRa0A",
        "outputId": "c46fa051-3f0d-4b70-a198-48ad27fe3059"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Lionel', 'Messi', 'and', 'Cristiano', 'Ronaldo', 'are', 'football', 'icons', '.', 'Messi', 'is', 'known', 'for', 'his', 'finesse', ',', 'while', 'Ronaldo', 'stands', 'out', 'for', 'his', 'power', '.', 'They', '’', 've', 'set', 'records', 'and', 'won', 'countless', 'awards', '.', 'Together', ',', 'they', 'define', 'a', 'legendary', 'rivalry', 'in', 'football', 'history', '.']\n",
            "Total Number of Tokens: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate token frequency\n",
        "freq_dist = FreqDist(tokens)\n",
        "print(\"Token Frequency:\", freq_dist)\n",
        "\n",
        "# Display each token with its frequency\n",
        "for token, frequency in freq_dist.items():\n",
        "    print(f\"{token}: {frequency}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ManvMMRpzs",
        "outputId": "6329818b-28ea-4df7-e769-731a4dd1e8b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Frequency: <FreqDist with 35 samples and 45 outcomes>\n",
            "Lionel: 1\n",
            "Messi: 2\n",
            "and: 2\n",
            "Cristiano: 1\n",
            "Ronaldo: 2\n",
            "are: 1\n",
            "football: 2\n",
            "icons: 1\n",
            ".: 4\n",
            "is: 1\n",
            "known: 1\n",
            "for: 2\n",
            "his: 2\n",
            "finesse: 1\n",
            ",: 2\n",
            "while: 1\n",
            "stands: 1\n",
            "out: 1\n",
            "power: 1\n",
            "They: 1\n",
            "’: 1\n",
            "ve: 1\n",
            "set: 1\n",
            "records: 1\n",
            "won: 1\n",
            "countless: 1\n",
            "awards: 1\n",
            "Together: 1\n",
            "they: 1\n",
            "define: 1\n",
            "a: 1\n",
            "legendary: 1\n",
            "rivalry: 1\n",
            "in: 1\n",
            "history: 1\n"
          ]
        }
      ]
    }
  ]
}